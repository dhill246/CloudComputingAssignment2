{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## rPlace Analysis\n",
    "by: Daniel, Ryan, and Toby"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "import gzip\n",
    "import shutil\n",
    "import os\n",
    "import pyarrow.csv as csv\n",
    "import pyarrow.parquet as pq\n",
    "import pyarrow as pa\n",
    "from pyarrow import parquet\n",
    "import re\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Unzipping files stored in ZipFiles/ and storing them in UnzippedFiles/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This script will unzip all the files within the ZipFiles folder\n",
    "source_directory = \"ZipFiles\"\n",
    "directory_to_extract_to = \"UnzippedFiles/\"\n",
    "\n",
    "# Loop over all files in the source directory\n",
    "for filename in os.listdir(source_directory):\n",
    "    if filename.endswith(\".gzip\"):\n",
    "        path_to_gzip_file = os.path.join(source_directory, filename)\n",
    "\n",
    "        # Remove \"\".gzip\" and everything before number \n",
    "        # from the filename for the output file\n",
    "        output_filename = filename[-11:-5] \n",
    "        output_file_path = os.path.join(directory_to_extract_to, output_filename)\n",
    "\n",
    "        with gzip.open(path_to_gzip_file, \"rb\") as gzip_file:\n",
    "            with open(output_file_path, \"wb\") as output_file:\n",
    "                shutil.copyfileobj(gzip_file, output_file)\n",
    "        print(f\"Decompressed {filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Combining into parquet (Toby's version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_coords(coord_str):\n",
    "    geometry = None\n",
    "    #split it up\n",
    "    coords = coord_str.split(',')\n",
    "    if len(coords) == 4:\n",
    "        #rectangle\n",
    "        geometry = 'rect'\n",
    "    elif len(coords) == 3:\n",
    "        #circle\n",
    "        geometry = 'circle'\n",
    "    x = int(re.search(r'-?\\d+', coords[0]).group())\n",
    "    y = int(re.search(r'-?\\d+', coords[1]).group())\n",
    "    return (x,y,geometry)\n",
    "\t\n",
    "source_directory = \"UnzippedFiles/\"\n",
    "output_parquet_file = \"rplace_new.parquet\"\n",
    "\n",
    "# Define schema for parquet\n",
    "schema = pa.schema([\n",
    "    pa.field(\"timestamp\", pa.timestamp(unit='ms')),\n",
    "    pa.field(\"user\", pa.string()),\n",
    "    #pa.field(\"coordinate\", pa.string()),\n",
    "    pa.field(\"pixel_color\", pa.string()),\n",
    "    pa.field(\"x\", pa.int16()),\n",
    "    pa.field(\"y\", pa.int16()),\n",
    "    pa.field(\"geometry\", pa.string())\n",
    "])\n",
    "\n",
    "# Initialize parquet writer\n",
    "writer = parquet.ParquetWriter(output_parquet_file, schema, compression=\"snappy\")\n",
    "\n",
    "for filename in os.listdir(source_directory):\n",
    "\n",
    "    # Make sure file being processed is a csv\n",
    "    if filename.endswith(\".csv\"):\n",
    "\n",
    "        # Join source directory with current filename\n",
    "        path_to_file = os.path.join(source_directory, filename)\n",
    "\n",
    "        # Read current csv        \n",
    "        print(\"Reading: \" + filename)\n",
    "        table = csv.read_csv(path_to_file)\n",
    "        \n",
    "        #Ensuring the date is in the proper format, requires removing UTC and redefining as timestamp in milliseconds\n",
    "        array = table['timestamp'].combine_chunks()\n",
    "        # Replace string ending with UTC\n",
    "        array = pa.compute.replace_substring_regex(array, \" UTC\", \"\")\n",
    "        # Convert to date\n",
    "        array = array.cast(pa.timestamp(unit='ms'))\n",
    "        # Put back in the table\n",
    "        table = table.set_column(table.schema.get_field_index(\"timestamp\"), \"timestamp\", array)\n",
    "        \n",
    "        #Create x,y,geometry and drop the coordinate column afterwards\n",
    "        #This takes the coordinates, makes a series, then applies a custom function to split into x,y coords and the type of geometry if any\n",
    "        coords = table['coordinate'].combine_chunks().to_pandas().apply(split_coords)\n",
    "        coords = pd.DataFrame(coords.tolist(), columns=['x','y','geometry'])\n",
    "\n",
    "        #add these columns in\n",
    "        table = table.append_column(\"x\", [coords['x']]) #stupid that you have to put these in a 2d array\n",
    "        table = table.append_column(\"y\", [coords['y']])\n",
    "        table = table.append_column(\"geometry\", [coords['geometry']])\n",
    "        #drop the coordinate column now\n",
    "        table = table.drop(['coordinate'])\n",
    "        \n",
    "        table = table.cast(schema)\n",
    "\n",
    "        # Write current csv to parquet\n",
    "        print(\"Writing: \" + filename)\n",
    "        writer.write_table(table)\n",
    "\n",
    "# Close parquet writer if still open\n",
    "if writer:\n",
    "    writer.close()\n",
    "\n",
    "\n",
    "print(\"Successfully combined into \" + output_parquet_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Aggregating data and outputting key files for further analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scan in newly created parquet file\n",
    "df = pl.scan_parquet(\"rplace_new.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by x and y coordinates and count occurrences\n",
    "grouped_df = df.group_by([\"x\", \"y\"]).agg(pl.count(\"user\").alias(\"count\")).sort(\"count\", descending=True)\n",
    "\n",
    "# Display the result\n",
    "top_pixels = grouped_df.head(100).collect()\n",
    "\n",
    "# Write out to csv\n",
    "top_pixels.write_csv(\"Highest used pixels.csv\",separator=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_df = df.group_by([\"user\"]).agg(pl.count(\"x\").alias(\"count\")).sort(\"count\", descending=True)\n",
    "\n",
    "# Display the result\n",
    "top_users = grouped_df.head(1000).collect()\n",
    "\n",
    "top_users.write_csv(\"Highest active users.csv\",separator=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_df = df.group_by([\"pixel_color\"]).agg(pl.count(\"x\").alias(\"count\")).sort(\"count\", descending=True)\n",
    "\n",
    "# Display the result\n",
    "top_colors = grouped_df.head(100).collect()\n",
    "\n",
    "top_colors.write_csv(\"Highest used colors.csv\",separator=\",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Visualization development and statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average interval between pixel placement\n",
    "grouped_df = df.filter(pl.col('user') == top_users['user'][2])\n",
    "user_activity = grouped_df.collect().to_pandas()\n",
    "user_activity_sort = user_activity.sort_values(by=['timestamp'],axis=0,ascending=True)\n",
    "user_activity_sort['timestamp diff'] = user_activity_sort['timestamp'].diff().fillna(pd.Timedelta(seconds=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_activity_sort.sort_values(by='timestamp diff',ascending=False)[0:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(user_activity_sort['timestamp diff'].mean())\n",
    "print(user_activity_sort['timestamp diff'].median())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Shotbow Bots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = df.filter((pl.col('timestamp') >= datetime(2023,7,25,18,14)) & (pl.col('timestamp') <= datetime(2023,7,25,18,15,50)))\n",
    "t.group_by([\"user\"]).agg(pl.count(\"x\").alias(\"count\")).sort(\"count\", descending=True).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tt = t.collect()\n",
    "tt.filter((pl.col('timestamp') >= datetime(2023,7,25,18,15,10)) & (pl.col('timestamp') <= datetime(2023,7,25,18,15,11)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ttt = tt.to_pandas()\n",
    "ttt.plot.scatter(x='x', y='y', s=2, c='blue', alpha=0.05)  # c is color, alpha is transparency\n",
    "\n",
    "plt.title('Pixel Positions on Shotbow Image Timeframe')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = t.filter((pl.col('x') > 500) & (pl.col('x') < 1075) & (pl.col('y') < -125) & (pl.col('y') > -300))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aa = a.group_by([\"user\"]).agg(pl.count(\"x\").alias(\"count\")).sort(\"count\", descending=True)\n",
    "aa.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plotnine import *\n",
    "\n",
    "colordf = pd.read_csv('Highest used colors.csv')  \n",
    "\n",
    "colordf['pixel_color'] = pd.Categorical(colordf['pixel_color'], categories=colordf['pixel_color'], ordered=True)\n",
    "# Create the plot using ggplot\n",
    "plot = (ggplot(colordf, aes(x='pixel_color', y='count', fill='pixel_color')) +\n",
    "        geom_bar(stat='identity') +  # Create bars with heights corresponding to count values\n",
    "        scale_fill_identity() +      # Use colors from the 'color' column\n",
    "        labs(x='pixel_color', y='Count', title='Sorted Colors') +  # Labels and title\n",
    "        theme_gray() +            # Minimalistic theme\n",
    "        theme(axis_text_x=element_blank(),legend_position='none'))  # Hide legend\n",
    "\n",
    "# Display the plot\n",
    "print(plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "userdf = pd.read_csv('Highest active users.csv')\n",
    "\n",
    "# Convert 'user' column to categorical variable with order based on 'count'\n",
    "userdf['user'] = pd.Categorical(userdf['user'], categories=userdf['user'], ordered=True)\n",
    "\n",
    "# Create the plot using ggplot\n",
    "plot = (ggplot(userdf[0:25], aes(x='user', y='count')) +\n",
    "        geom_bar(stat='identity',fill='#FF5700') +  # Create bars with heights corresponding to count values\n",
    "        labs(x='User', y='Count', title='Highest Active Users') +  # Labels and title\n",
    "        theme_minimal() +            # Minimalistic theme\n",
    "        theme(axis_text_x=element_blank(),  # Rotate x-axis labels for better readability\n",
    "              legend_position='none'))  # Hide legend\n",
    "\n",
    "# Display the plot\n",
    "print(plot)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
